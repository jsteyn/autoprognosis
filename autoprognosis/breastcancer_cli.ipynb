{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Autoprognosis\n",
    "\n",
    "## Automated Clinical Prognostic Modeling \n",
    "\n",
    "This tutorial shows how to use [Autoprognosis](https://arxiv.org/abs/1802.07207). We are using the UCI spam dataset.\n",
    "\n",
    "See [installation instructions](../../doc/install.md) to install the dependencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import initpath_ap\n",
    "initpath_ap.init_sys_path()\n",
    "import utilmlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load dataset.\n",
    "* Convert the id column to an object type\n",
    "* Set the target column\n",
    "* Show the first five samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_csv = 'breastcancer_datasets_180_408_data-csv.csv'.format(utilmlab.get_data_dir())\n",
    "df = pd.read_csv(fn_csv)\n",
    "df['id'] = df['id'].astype(object)\n",
    "print(df.dtypes)\n",
    "target = 'diagnosis'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run autoprognosis for a number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n",
      "R[write to console]: Loading required package: missForest\n",
      "\n",
      "R[write to console]: Loading required package: randomForest\n",
      "\n",
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "R[write to console]: Loading required package: foreach\n",
      "\n",
      "R[write to console]: Loading required package: itertools\n",
      "\n",
      "R[write to console]: Loading required package: iterators\n",
      "\n",
      "R[write to console]: Loading required package: softImpute\n",
      "\n",
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Loaded softImpute 1.4\n",
      "\n",
      "\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "[ XGBoost ]\n",
      "[ BernoullinNaiveBayes ]\n",
      "[ LogisticRegression ]\n",
      "Iteration number: 1 2s (2s) (5s), Current pipelines:  [[[ XGBoost ]]], [[[ BernoullinNaiveBayes ]]], [[[ LogisticRegression ]]], BO objective: 0.0\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LDA ]\n",
      "Iteration number: 2 3s (2s) (5s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ MultinomialNaiveBayes ]]], [[[ LDA ]]], BO objective: -1.0000000000000102\n",
      "[ XGBoost ]\n",
      "[ BernoullinNaiveBayes ]\n",
      "[ LDA ]\n",
      "Iteration number: 3 5s (2s) (5s), Current pipelines:  [[[ XGBoost ]]], [[[ BernoullinNaiveBayes ]]], [[[ LDA ]]], BO objective: -1.3996232923843617\n",
      "\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "[ Gradient Boosting ]\n",
      "[ Bagging ]\n",
      "[ KNN ]\n",
      "Iteration number: 1 29s (29s) (88s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ Bagging ]]], [[[ KNN ]]], BO objective: 0.0\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ KNN ]\n",
      "Iteration number: 2 32s (16s) (48s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ MultinomialNaiveBayes ]]], [[[ KNN ]]], BO objective: -1.0\n",
      "[ XGBoost ]\n",
      "[ AdaBoost ]\n",
      "[ QDA ]\n",
      "Iteration number: 3 58s (19s) (58s), Current pipelines:  [[[ XGBoost ]]], [[[ AdaBoost ]]], [[[ QDA ]]], BO objective: -1.414213562373094\n",
      "\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "[ Gradient Boosting ]\n",
      "[ BernoullinNaiveBayes ]\n",
      "[ GaussianNaiveBayes ]\n",
      "Iteration number: 1 2s (2s) (5s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ BernoullinNaiveBayes ]]], [[[ GaussianNaiveBayes ]]], BO objective: 0.0\n",
      "[ XGBoost ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ GaussianNaiveBayes ]\n",
      "Iteration number: 2 4s (2s) (5s), Current pipelines:  [[[ XGBoost ]]], [[[ MultinomialNaiveBayes ]]], [[[ GaussianNaiveBayes ]]], BO objective: -1.0000000000000007\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ DecisionTrees ]\n",
      "Iteration number: 3 5s (2s) (5s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ MultinomialNaiveBayes ]]], [[[ DecisionTrees ]]], BO objective: -1.4142112765004609\n",
      "\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "[ NeuralNet ]\n",
      "[ AdaBoost ]\n",
      "[ QDA ]\n",
      "Iteration number: 1 9s (9s) (27s), Current pipelines:  [[[ NeuralNet ]]], [[[ AdaBoost ]]], [[[ QDA ]]], BO objective: 0.0\n",
      "[ NeuralNet ]\n",
      "[ AdaBoost ]\n",
      "[ QDA ]\n",
      "Iteration number: 2 24s (12s) (36s), Current pipelines:  [[[ NeuralNet ]]], [[[ AdaBoost ]]], [[[ QDA ]]], BO objective: -1.0000000000000002\n",
      "[ NeuralNet ]\n",
      "[ AdaBoost ]\n",
      "[ LogisticRegression ]\n",
      "Iteration number: 3 38s (13s) (38s), Current pipelines:  [[[ NeuralNet ]]], [[[ AdaBoost ]]], [[[ LogisticRegression ]]], BO objective: -1.3889105391407615\n",
      "\n",
      "[ Gradient Boosting ]\n",
      "[ MultinomialNaiveBayes ]\n",
      "[ LinearSVM ]\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n",
      "[ Gradient Boosting ]\n",
      "[ BernoullinNaiveBayes ]\n",
      "[ KNN ]\n",
      "Iteration number: 1 1s (1s) (4s), Current pipelines:  [[[ Gradient Boosting ]]], [[[ BernoullinNaiveBayes ]]], [[[ KNN ]]], BO objective: 0.0\n",
      "[ XGBoost ]\n",
      "[ AdaBoost ]\n",
      "[ QDA ]\n",
      "Iteration number: 2 6s (3s) (9s), Current pipelines:  [[[ XGBoost ]]], [[[ AdaBoost ]]], [[[ QDA ]]], BO objective: -1.0000000000000002\n",
      "[ Random Forest ]\n",
      "[ AdaBoost ]\n",
      "[ QDA ]\n",
      "Iteration number: 3 44s (15s) (44s), Current pipelines:  [[[ Random Forest ]]], [[[ AdaBoost ]]], [[[ QDA ]]], BO objective: -1.4131006748072685\n",
      "\n",
      "{'model_list': [<models.classifiers.XGboost object at 0x7f969687ecc0>], 'explained': '[ *GBoost is an open-source software library which provides the gradient boosting framework for C++, Java, Python, R, and Julia.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ XGBoost ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.RandomForest object at 0x7f968025bbe0>], 'explained': '[ *Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ Random Forest ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "{'model_list': [<models.classifiers.QDA_ object at 0x7f9698b32860>], 'explained': '[ *The perceptron is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not).* ]', 'image_name': None, 'classes': None, 'num_stages': 1, 'pipeline_stages': ['classifier'], 'name': '[ QDA ]', 'analysis_mode': None, 'analysis_type': None}\n",
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  0.9999989373041451  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  1.6656693864140657  |      +ve      |        \n",
      "  \u001b[1mMat52.     \u001b[0;0m  |  value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |    1.0  |      +ve      |        \n",
      "  \u001b[1mMat52.     \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1mvariance   \u001b[0;0m  |  0.9999992382292149  |      +ve      |        \n",
      "  \u001b[1mlengthscale\u001b[0;0m  |  1.3344904355427256  |      +ve      |        \n",
      "R[write to console]: Warning messages:\n",
      "\n",
      "R[write to console]: 1: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 2: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 3: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 4: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 5: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 6: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 7: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 8: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 9: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n",
      "R[write to console]: 10: \n",
      "R[write to console]: In simpute.als(x, J, thresh, lambda, maxit, trace.it, warm.start,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Convergence not achieved by 100 iterations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "python_exe = 'python3' # on some platforms the name of the python3.6 executable is python or python3.6\n",
    "odir = \".\"   # output directory\n",
    "verboselevel = 0  \n",
    "niter = 3  # number of interations\n",
    "nstage = 1 # number of components in the pipeline: 1:classifiers, 2:feature processing + classifier: 3:imputation + ...\n",
    "acquisition_type = 'MPI' # default and prefered is LCB but this generates excessive warnings, MPI is a good compromise.\n",
    "!python3 autoprognosis.py -i {fn_csv} -o {odir} --target {target} --verbose {verboselevel} --nstage 1 --it  {niter} --acquisitiontype {acquisition_type}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\r\n",
      "\r\n",
      "classifier      aucroc 0.973\r\n",
      "classifier      aucprc 0.965\r\n",
      "ensemble        aucroc 0.974\r\n",
      "ensemble        aucprc 0.967\r\n",
      "\r\n",
      "Report\r\n",
      "\r\n",
      "best score single pipeline (while fitting)    0.988\r\n",
      "model_names_single_pipeline                   [ XGBoost ]\r\n",
      "best ensemble score (while fittng)            0.988\r\n",
      "ensemble_pipelines                            ['[ XGBoost ]', '[ Gradient Boosting ]', '[ Gradient Boosting ]']\r\n",
      "ensemble_pipelines_weight                     [0.5107080391824953, 0.15186601373783712, 0.33742594707966755]\r\n",
      "optimisation_metric                           aucroc\r\n",
      "hyperparameter_properties                     [{'name': 'XGBoost', 'hyperparameters': {'model': \"XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\\n              importance_type='gain', interaction_constraints=None,\\n              learning_rate=0.08544152889949688, max_delta_step=0, max_depth=3,\\n              min_child_weight=1, missing=nan, monotone_constraints=None,\\n              n_estimators=199, n_jobs=0, num_parallel_tree=1,\\n              objective='binary:logistic', random_state=0, reg_alpha=0,\\n              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\\n              validate_parameters=False, verbosity=None)\"}}]\r\n",
      "acquisition_type                              MPI\r\n",
      "kernel_members                                0 ['XGBoost', 'Gradient Boosting', 'Random Forest', 'Neural Network']\r\n",
      "kernel_members                                1 ['Multinomial Naive Bayes', 'Bernoulli Naive Bayes', 'Bagging', 'Adaboost']\r\n",
      "kernel_members                                2 ['Linear SVM', 'KNN', 'Decision Trees', 'Perceptron', 'Logistic Regression', 'Gauss Naive Bayes', 'QDA', 'LDA']\r\n",
      "classes dataset                               [0, 1]\r\n",
      "features                                      ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_%3B', 'char_freq_%28', 'char_freq_%5B', 'char_freq_%21', 'char_freq_%24', 'char_freq_%23', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total']\r\n",
      "samples                                       4601\r\n",
      "(0, {'name': 'initial', 'aucroc': 0.9716112571516933})\r\n",
      "sort by aucroc\r\n",
      "# 50\r\n",
      "# 13\r\n",
      "\r\n",
      "Average performance per classifier (ignoring hyperparameters):\r\n",
      "\r\n",
      "  0 XGBoost                                              5 0.973 0.966\r\n",
      "  1 Gradient Boosting                                    5 0.972 0.962\r\n",
      "  2 Random Forest                                        3 0.969 0.964\r\n",
      "  3 Bagging                                              3 0.962 0.955\r\n",
      "  4 BernoullinNaiveBayes                                 4 0.947 0.935\r\n",
      "  5 LDA                                                  4 0.937 0.897\r\n",
      "  6 MultinomialNaiveBayes                                4 0.840 0.777\r\n",
      "  7 NeuralNet                                            2 0.839 0.778\r\n",
      "  8 KNN                                                  3 0.777 0.645\r\n",
      "  9 LogisticRegression                                   3 0.668 0.547\r\n",
      " 10 AdaBoost                                             4 0.622 0.555\r\n",
      " 11 Perceptron                                           1 0.500 0.000\r\n",
      " 12 DecisionTrees                                        4 0.500 0.000\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!{python_exe} autoprognosis_report.py -i {odir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
